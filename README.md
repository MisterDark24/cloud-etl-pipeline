# 锔 Cloud ETL Pipeline

Proyecto final para la materia de **Computaci贸n en la Nube**, enfocado en la construcci贸n de un pipeline ETL utilizando **Pentaho Data Integration (Spoon)**.

---

##  Descripci贸n

Este proyecto permite cargar archivos CSV a una base de datos relacional mediante transformaciones ETL desarrolladas en Pentaho. Se incluyen validaciones, control de errores, env铆o de notificaciones por correo y gesti贸n de logs. Todo el proceso es automatizable y escalable.

---

##  Estructura del repositorio

```
cloud-etl-pipeline/
 transformations/         # Archivos .ktr (transformaciones ETL)
 jobs/                    # Archivos .kjb (jobs de control de flujo)
 sql/                     # Scripts SQL
 logs/                    # Logs generados durante la ejecuci贸n
 data/                    # Archivos de entrada de datos (opcional)
 README.md
 .gitignore
```

---

## 锔 Tecnolog铆as utilizadas

| Tecnolog铆a                           | Uso principal                                                                  |
|--------------------------------------|--------------------------------------------------------------------------------|
| **VMware Workstation**               | Virtualizaci贸n del entorno de desarrollo en una m谩quina local                  |
| **Linux (Ubuntu)**                   | Sistema operativo para el desarrollo, pruebas y ejecuci贸n del pipeline         |
| **Pentaho Data Integration (Spoon)** | Orquestaci贸n del proceso ETL, validaci贸n de datos y env铆o de notificaciones    |
| **MySQL**                            | Base de datos relacional para almacenamiento estructurado y an谩lisis posterior |
| **Git & GitHub**                     | Control de versiones y gesti贸n del repositorio del proyecto                    |

---


